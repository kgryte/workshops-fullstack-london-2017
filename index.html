<!doctype html>
<html>
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">

	<title>Workshop | FullStack London | 2017</title>
	<meta name="description" content="The JavaScript Data Science Survival Kit. Workshop for FullStack London 2017. The fields of machine learning and data science can appear intractable and overwhelming, often leaving newcomers at a loss for knowing where to begin. However, once you learn basic principles and workflows, you will see many opportunities where these techniques can help you in your projects. You can better understand your users, embed a recommendation engine into your application, or easily ship dashboards including statistical summaries and stunning visualizations. The rise of Node.js and Electron are powering a new era where JavaScript continues to expand beyond the browser and becomes a critical component of server and desktop applications. With JavaScript being everywhere, one of the emerging next frontiers for JavaScript world domination is data science. In this workshop, you will learn how to utilize the JavaScript open-source library stdlib for various data science tasks. Through a series of brief exercises, attendees will get a hands-on introduction, ranging from analytics to machine learning to exploratory data analysis and visualization. For example, you will investigate the accuracy of the native JavaScript Math functions, build a spam classifier, and generate synthetic texts using Markov chains. After completing this workshop, you will have a solid understanding of what kind of problems they can approach by which techniques. Furthermore, you will have experience in conducting a full analysis from start to end, i.e., exploring, cleaning, transforming, and analyzing data with state-of-the-art techniques. The workshop will close with an outline of future steps for data science in JavaScript and opportunities for community development of next-generation tools.">
	<meta name="author" content="stdlib">

	<meta name="apple-mobile-web-app-capable" content="yes">
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

	<!-- Icons -->
	<link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
	<link rel="manifest" href="manifest.json">
	<link rel="mask-icon" href="safari-pinned-tab.svg" color="#5bbad5">
	<meta name="theme-color" content="#ffffff">

	<!-- Facebook Open Graph -->
	<meta property="og:type" content="website">
	<meta property="og:site_name" content="stdlib">
	<meta property="og:url" content="https://stdlib-js.github.io/workshops-fullstack-london-2017">
	<meta property="og:title" content="The JavaScript Data Science Survival Kit.">
	<meta property="og:description" content="Workshop for FullStack London 2017.">
	<meta property="og:locale" content="en_US">
	<meta property="og:image" content="">

	<!-- Twitter -->
	<meta name="twitter:card" content="The JavaScript Data Science Survival Kit.">
	<meta name="twitter:site" content="@stdlibjs">
	<meta name="twitter:url" content="https://stdlib-js.github.io/workshops-fullstack-london-2017">
	<meta name="twitter:title" content="The JavaScript Data Science Survival Kit.">
	<meta name="twitter:description" content="Workshop for FullStack London 2017.">
	<meta name="twitter:image" content="">

	<!-- Webcomponents polyfills. Note that all HTML imports must come AFTER the polyfill to ensure that the imports are properly loaded. -->
	<script type="text/javascript" src="components/webcomponentsjs/webcomponents-lite.min.js"></script>

	<!-- Styles -->
	<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:300,400,400italic,500,500italic,700,700italic|Roboto+Mono:400,700">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css" integrity="sha384-wITovz90syo1dJWVh32uuETPVEtGigN07tkttEqPv+uR2SE/mbQcG7ATL28aI9H0" crossorigin="anonymous">

	<style>
		body {
			font-family: "Roboto", "Helvetica Neue", Helvetica, Arial;
		}
	</style>

	<!-- HTML imports -->
	<link rel="import" href="components/iron-icons/iron-icons.html">
	<link rel="import" href="components/paper-button/paper-button.html">
	<link rel="import" href="components/codelab-components/google-codelab-elements.html">
</head>
<body unresolved class="fullbleed">

	<google-codelab title="Workshop" feedback-link="https://github.com/stdlib-js/workshops-fullstack-london-2017/issues" environment="web">

		<!-- Overview -->

		<google-codelab-step label="Overview" duration="2">
			<p>
				Welcome to <i>The JavaScript Data Science Survival Kit</i> workshop! In this workshop, you will get a hands-on introduction to data science in JavaScript.
			</p>

			<h3>What you'll learn</h3>
			<ul class="checklist">
				<li>
					How to use the <a title="A standard library for Node.js and JavaScript" href="https://github.com/stdlib-js/stdlib">stdlib</a> REPL
				</li>
				<li>
					Where to find help and documentation
				</li>
				<li>
					What features and tools are available for working with data
				</li>
				<li>
					How to plot data
				</li>
				<li>
					How to generate <a title="Pseudorandom number generators" href="https://en.wikipedia.org/wiki/Pseudorandom_number_generator">pseudorandom numbers</a> and associated <a title="List of probability distributions" href="https://en.wikipedia.org/wiki/List_of_probability_distributions">statistical distributions</a>
				</li>
				<li>
					How to perform <a title="Statistical hypothesis testing" href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">statistical tests</a>
				</li>
				<li>
					How to build a <a title="Email filtering" href="https://en.wikipedia.org/wiki/Email_filtering">spam classifier</a>
				</li>
				<li>
					How to perform <a title="Kernel density estimation" href="https://en.wikipedia.org/wiki/Kernel_density_estimation">kernel density estimation</a>
				</li>
			</ul>

			<h3>What you'll need</h3>
			<ul>
				<li>
					Internet access
				</li>
				<li>
					Basic understanding of HTML, CSS, and web development
				</li>
				<li>
					Intermediate understanding of JavaScript
				</li>
				<li>
					A modern browser (e.g., <a title="Chrome for desktop" href="https://www.google.com/chrome/browser/desktop/index.html">Chrome</a>; preferably the latest version)
				</li>
				<li>
					Familiarity with <a title="Chrome developer tools" href="https://developer.chrome.com/devtools">browser developer tools</a>, including the <a title="JavaScript console" href="https://developers.google.com/web/tools/chrome-devtools/console/">JavaScript console</a>
				</li>
			</ul>
		</google-codelab-step>

		<!-- Survey -->

		<google-codelab-step label="Survey" duration="2">
			<p>
				Before beginning, help us better understand your motivations and skill level by completing this short <strong>anonymous</strong> survey.
			</p>
			<google-codelab-survey survey-id="audience">
				<h4>Which statement best describes why you are taking this workshop?</h4>
				<paper-radio-group>
					<paper-radio-button>I am excited because I get to do data science in <em>JavaScript</em>!</paper-radio-button>
					<paper-radio-button>I am excited because I get to use JavaScript to do <em>data science</em>!</paper-radio-button>
				</paper-radio-group>

				<h4>How would you rate your experience with JavaScript?</h4>
				<paper-radio-group>
					<paper-radio-button>Beginner</paper-radio-button>
					<paper-radio-button>Intermediate</paper-radio-button>
					<paper-radio-button>Advanced</paper-radio-button>
				</paper-radio-group>

				<h4>How would you rate your experience with data visualization?</h4>
				<paper-radio-group>
					<paper-radio-button>Beginner</paper-radio-button>
					<paper-radio-button>Intermediate</paper-radio-button>
					<paper-radio-button>Advanced</paper-radio-button>
				</paper-radio-group>

				<h4>How would you rate your experience with mathematics?</h4>
				<paper-radio-group>
					<paper-radio-button>Beginner</paper-radio-button>
					<paper-radio-button>Intermediate</paper-radio-button>
					<paper-radio-button>Advanced</paper-radio-button>
				</paper-radio-group>

				<h4>How would you rate your experience with statistics?</h4>
				<paper-radio-group>
					<paper-radio-button>Beginner</paper-radio-button>
					<paper-radio-button>Intermediate</paper-radio-button>
					<paper-radio-button>Advanced</paper-radio-button>
				</paper-radio-group>

				<h4>How would you rate your experience with machine learning?</h4>
				<paper-radio-group>
					<paper-radio-button>Beginner</paper-radio-button>
					<paper-radio-button>Intermediate</paper-radio-button>
					<paper-radio-button>Advanced</paper-radio-button>
				</paper-radio-group>

				<h4>Have you ever used Python for numeric computing (e.g., data analysis, machine learning, etc.)?</h4>
				<paper-radio-group>
					<paper-radio-button>Yes</paper-radio-button>
					<paper-radio-button>No</paper-radio-button>
				</paper-radio-group>

				<h4>Have you ever used MATLAB for numeric computing (e.g., data analysis, machine learning, etc.)?</h4>
				<paper-radio-group>
					<paper-radio-button>Yes</paper-radio-button>
					<paper-radio-button>No</paper-radio-button>
				</paper-radio-group>

				<h4>Have you ever used R for numeric computing (e.g., data analysis, machine learning, etc.)?</h4>
				<paper-radio-group>
					<paper-radio-button>Yes</paper-radio-button>
					<paper-radio-button>No</paper-radio-button>
				</paper-radio-group>

				<h4>Have you ever used Julia for numeric computing (e.g., data analysis, machine learning, etc.)?</h4>
				<paper-radio-group>
					<paper-radio-button>Yes</paper-radio-button>
					<paper-radio-button>No</paper-radio-button>
				</paper-radio-group>
			</google-codelab-survey>
		</google-codelab-step>

		<!-- REPL -->

		<google-codelab-step label="REPL" duration="15">
			<p>
				A <a title="REPL" href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop">read-eval-print-loop</a> (REPL) is an interactive programming environment that takes single user inputs, evaluates those inputs, and returns results to the user. In this lab, you will explore the <a title="A standard library for Node.js and JavaScript" href="https://github.com/stdlib-js/stdlib">stdlib</a> REPL.
			</p>
			<aside class="special">
				<p>
					<a title="A standard library for Node.js and JavaScript" href="https://github.com/stdlib-js/stdlib">stdlib</a> is a standard library for Node.js and JavaScript, with an emphasis on numeric computing. The library includes an extensive collection of standard library mathematical functions, utilities for manipulating floating-point numbers and transforming data, seedable pseudorandom number generators, BLAS interfaces, sample datasets, plotting, string utilities, and much more. See the <a title="A standard library for Node.js and JavaScript" href="https://github.com/stdlib-js/stdlib">repository</a> for more information.
				</p>
			</aside>

			<h3>Setup</h3>
			<p>
				To access the <a title="REPL" href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop">REPL</a>, open the JavaScript <a title="Accessing the JavaScript console in Chrome" href="https://developer.chrome.com/devtools#access">console</a> for <strong>this</strong> page.
			</p>
			<aside class="special">
				<p>
					For example, in Chrome on Mac, press <code>Cmd+Alt+J</code>, and, in Chrome on Windows, press <code>Ctrl+Shift+J</code>.
				</p>
			</aside>
			<p>
				Once the <a title="Accessing the JavaScript console in Chrome" href="https://developer.chrome.com/devtools#access">console</a> is open, we recommend arranging the windows side-by-side to facilitate moving between this page and the <a title="Accessing the JavaScript console in Chrome" href="https://developer.chrome.com/devtools#access">console</a> as you progress through the various exercises.
			</p>
			<div align="center">
				<img alt="Side-by-side window layout" src="img/setup_layout.png" style="max-width: 800px;">
			</div>
			<p>
				<strong>WARNING:</strong> refreshing the page will clear all REPL history.
			</p>

			<h3>Getting Started</h3>
			<p>
				If you are unfamiliar with the <a title="Accessing the JavaScript console in Chrome" href="https://developer.chrome.com/devtools#access">console</a>, the <a title="Accessing the JavaScript console in Chrome" href="https://developer.chrome.com/devtools#access">console</a> provides an interactive environment for running JavaScript in the browser. Try entering the following in the <a title="Accessing the JavaScript console in Chrome" href="https://developer.chrome.com/devtools#access">console</a> window:
			</p>
			<pre><code language="javascript">2 + 2</code></pre>
			<p>
				When you press <code>enter</code>, the <a title="Accessing the JavaScript console in Chrome" href="https://developer.chrome.com/devtools#access">console</a> will <strong>read</strong> the input, <strong>evaluate</strong> the input, and <strong>print</strong> the results.
			</p>
			<pre><code language="javascript">
&gt; 2 + 2
4</code></pre>
			<aside class="special">
				<p>
					Throughout the workshop, we will often include the <code>&gt;</code> symbol for expressions entered in the <a title="Accessing the JavaScript console in Chrome" href="https://developer.chrome.com/devtools#access">console</a>. Doing so helps distinguish between the expressions which are evaluated and the printed results. When entering expressions, <strong>omit</strong> the leading <code>&gt;</code> symbol.
				</p>
			</aside>
			<p>
				<a title="A standard library for Node.js and JavaScript" href="https://github.com/stdlib-js/stdlib">stdlib</a> augments the <a title="Accessing the JavaScript console in Chrome" href="https://developer.chrome.com/devtools#access">console</a> by exposing all library functionality within the global namespace. For example, to compute the <a title="Error function" href="https://en.wikipedia.org/wiki/Error_function">error function</a> for <code>1.5</code>
			</p>
			<pre><code language="javascript">
&gt; base.erf( 1.5 )
0.9661051464753108</code></pre>
			<p>
				Or to get the current time (in seconds) since the <a title="Unix epoch" href="https://en.wikipedia.org/wiki/Unix_time">Unix epoch</a>
			</p>
			<pre><code language="javascript">
&gt; now()</code></pre>
			<p>
				To list library functionality, enter
			</p>
			<pre><code language="javascript">
&gt; namespace()</code></pre>
			<h3>Help</h3>
			<p>
				One of the key features of <a title="A standard library for Node.js and JavaScript" href="https://github.com/stdlib-js/stdlib">stdlib</a> is the inclusion of REPL help documentation, which is accessed via the <code>help()</code> command.
			</p>
			<aside class="special">
				<p>
					In Firefox, the <code>help()</code> command is aliased as <code>_help()</code> due to a name conflict with one of Firefox's <a title="Firefox helper commands" href="https://developer.mozilla.org/en-US/docs/Tools/Web_Console/The_command_line_interpreter">helper commands</a>.
				</p>
			</aside>
			<p>
				For example, to access the help documentation for <code>base.erf</code>
			</p>
			<pre><code language="javascript">
&gt; help( base.erf )</code></pre>
			<p>
				All REPL help documentation follows the same general structure, providing examples, related functionality, and top-level, parameter, and return value descriptions.
			</p>
			<div align="center">
				<img alt="REPL help example" src="img/repl_help_example.png" style="max-width: 600px;">
			</div>

			<h3>Exercises</h3>
			<ul>
				<li>
					Familiarize yourself with REPL functionality by viewing the help documentation for a variety of exposed functions.
				</li>
				<li>
					Based on the example for <code>countBy()</code>, count the number of names in the <code>FEMALE_FIRST_NAMES_EN()</code> dataset which begin with a given letter. The result should be an object with letters as keys (e.g., <code>a</code>, <code>b</code>, <code>c</code>, <code>d</code>, ...) and counts as values.
				</li>
				<li>
					Similar to the previous exercise, use the <code>groupBy()</code> function to group names according to first letter.
				</li>
				<li>
					Similar to the previous exercise, use the <code>tabulateBy()</code> function to generate a frequency table of first letter occurrences.
				</li>
			</ul>

			<h3>Survey</h3>
			<google-codelab-survey survey-id="repl">
				<h4>How often do you use either the JavaScript console or Node.js REPL?</h4>
				<paper-radio-group>
					<paper-radio-button>Never</paper-radio-button>
					<paper-radio-button>Rarely</paper-radio-button>
					<paper-radio-button>Sometimes</paper-radio-button>
					<paper-radio-button>Frequently</paper-radio-button>
					<paper-radio-button>Everyday</paper-radio-button>
				</paper-radio-group>

				<h4>Did you find this lab useful?</h4>
				<paper-radio-group>
					<paper-radio-button>Not useful</paper-radio-button>
					<paper-radio-button>Somewhat useful</paper-radio-button>
					<paper-radio-button>Useful</paper-radio-button>
					<paper-radio-button>Very useful</paper-radio-button>
				</paper-radio-group>

				<h4>How do you feel about the length of this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Too short</paper-radio-button>
					<paper-radio-button>Just right</paper-radio-button>
					<paper-radio-button>Too long</paper-radio-button>
				</paper-radio-group>

				<h4>Apart from the final exercises, how difficult did you find this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Very Easy</paper-radio-button>
					<paper-radio-button>Easy</paper-radio-button>
					<paper-radio-button>Just Right</paper-radio-button>
					<paper-radio-button>Difficult</paper-radio-button>
					<paper-radio-button>Very Difficult</paper-radio-button>
				</paper-radio-group>

				<h4>How difficult did you find the exercises for this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Very Easy</paper-radio-button>
					<paper-radio-button>Easy</paper-radio-button>
					<paper-radio-button>Just Right</paper-radio-button>
					<paper-radio-button>Difficult</paper-radio-button>
					<paper-radio-button>Very Difficult</paper-radio-button>
				</paper-radio-group>

				<h4>Are you more likely to use either the JavaScript console or the Node.js REPL after completing this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>No</paper-radio-button>
					<paper-radio-button>Maybe</paper-radio-button>
					<paper-radio-button>Yes</paper-radio-button>
				</paper-radio-group>
			</google-codelab-survey>

		</google-codelab-step>

		<!-- Plotting -->

		<google-codelab-step label="Plotting" duration="25">
			<p>
				A <a title="Plot" href="https://en.wikipedia.org/wiki/Plot_%28graphics%29">plot</a> is a graphical technique used to represent a data set. The most common representation is a <a title="Graph" href="https://en.wikipedia.org/wiki/Graph_of_a_function">graph</a> showing the relationship between two or more variables.
			</p>
			<div align="center">
				<img alt="Plot example" src="img/plot_example.png" style="max-width: 800px;">
			</div>
			<p>
				Plots are critical for gaining insight into data sets. Plots facilitate testing assumptions, selecting and validating models, identifying relationships, detecting outliers, and communicating results. And importantly, plots as <a title="Statistical graphics" href="https://en.wikipedia.org/wiki/Statistical_graphics">statistical graphics</a> (i.e., graphs which visualize quantitative data) provide insight into the underlying structure of data.
			</p>
			<p>
				Statistical graphics have four main objectives:
			</p>
			<ul>
				<li>Exploration</li>
				<li>Communication</li>
				<li>Validation</li>
				<li>Structural Insight</li>
			</ul>
			<p>
				 In this lab, you will use the <a title="A standard library for Node.js and JavaScript" href="https://github.com/stdlib-js/stdlib">stdlib</a> to generate plots and explore data.
			</p>

			<h3>Getting Started</h3>
			<p>
				To begin, we need to create some simple data sets (feel free to use your own numeric values).
			</p>
			<pre><code language="javascript">
&gt; var x = [ 1, 2, 3 ];
&gt; var y = [ 1, 0, 1 ];</code></pre>
			<p>
				Now that we have some data, let us plot it! To do so, we must first create a plot instance.
			</p>
			<pre><code language="javascript">
&gt; var plt1 = plot( [x], [y] )</code></pre>
			<p>
				At this point, nothing is rendered. To render the plot,
			</p>
			<pre><code language="javascript">
&gt; var vtree = plt1.render()</code></pre>
			<p>
				The output of the <code>render()</code> method is <a title="Virtual DOM" href="https://github.com/Matt-Esch/virtual-dom">Virtual DOM</a>, which is a declarative way of representing the DOM.
			</p>
			<aside class="special">
				<p>
					<a title="Virtual DOM" href="https://github.com/Matt-Esch/virtual-dom">Virtual DOM</a> is a JavaScript DOM model which supports element creation, diff computation, and patch operations for efficient re-rendering. <a title="Virtual DOM" href="https://github.com/Matt-Esch/virtual-dom">Virtual DOM</a> is a convenient abstraction for plotting, as the model enables batched updates, performant rendering, and efficient serialization and provides an intermediate representation suitable for both client-side and server-side plot rendering.
				</p>
			</aside>
			<p>
				To generate HTML, we need to use <code>vdom2html()</code>, which translates <a title="Virtual DOM" href="https://github.com/Matt-Esch/virtual-dom">Virtual DOM</a> to HTML.
			</p>
			<pre><code language="javascript">
&gt; var html = vdom2html( vtree )</code></pre>
			<p>
				Now that we have rendered our plot and generated HTML, we need to generate the view (i.e., insert the plot into our page). To do so, we must first select the element into which we want to insert our plot. For convenience, we have already created a placeholder element. To select the element,
			</p>
			<pre><code language="javascript">
&gt; var el1 = document.querySelector( '#basic-plot' )</code></pre>
			<p>
				To insert the plot,
			</p>
			<pre><code language="javascript">
&gt; el1.innerHTML = html</code></pre>
			<figure id="basic-plot" align="center">
				<img alt="placeholder" src="img/plot_placeholder.png" style="max-width:400px;">
				<figcaption>Figure #basic-plot: A basic plot.</figcaption>
			</figure>
			<p>
				The plot view should look similar to the following (assuming the same data):
			</p>
			<figure align="center">
				<img alt="Basic plot" src="img/basic_plot.png" style="max-width: 600px;">
				<figcaption>Figure E1: Expected plot.</figcaption>
			</figure>

			<h3>Plot Types</h3>
			<p>
				In order to better familiarize ourselves with the plot API, let us create a few customized plots. As before, we will create some data, but this time we will generate random data using <code>base.random.randn()</code>, which is a <a title="Pseudorandom number generator" href="https://en.wikipedia.org/wiki/Pseudorandom_number_generator">pseudorandom number generator</a> (PRNG) for generating <a title="Normal distribution" href="https://en.wikipedia.org/wiki/Normal_distribution">normally distributed</a> pseudorandom numbers (i.e., numbers which, when combined in aggregate, form a bell-shaped curve).
			</p>
			<aside class="special">
				<p>
					A pseudorandom number generator (PRNG) is an algorithm for generating number sequences whose properties approximate the properties of random number sequences. A PRNG does not generate a truly random sequence because a PRNG is completely determined by its initial value, a <i>seed</i>. Because PRNGs are deterministic, a PRNG is also known as a <i>deterministic random bit generator</i> (DRBG).
				</p>
			</aside>
			<pre><code language="javascript">
&gt; var x = new Float64Array( 100 );
&gt; var y = new Float64Array( 100 );
&gt; inmap( x, base.random.randn );
&gt; inmap( y, base.random.randn );</code></pre>
			<p>
				And, as before, we will create a new plot using the <code>plot()</code> function.
			</p>
			<pre><code language="javascript">
&gt; var plt2 = plot( [x], [y] );</code></pre>
			<p>
				We can customize the plot instance by setting various plot properties. For instance, to set the plot <i>title</i>, we set the <code>title</code> property.
			</p>
			<pre><code language="javascript">
&gt; plt2.title = 'Scatter';</code></pre>
			<p>
				To generate a <a title="Scatter plot" href="https://en.wikipedia.org/wiki/Scatter_plot">scatter plot</a> rather than a <a title="Line chart" href="https://en.wikipedia.org/wiki/Line_chart">line chart</a> (see above), we disable the plot <i>line style</i> and specify a plot <i>symbol</i> (i.e., a visual encoding for each datum).
			</p>
			<pre><code language="javascript">
&gt; plt2.lineStyle = 'none';
&gt; plt2.symbols = 'closed-circle';</code></pre>
			<p>
				By default, a plot "hugs" the data, meaning that axis limits are defined by the minimum and maximum data values along a given axis. To override this behavior, we can set plot properties which explicitly define axis limits.
			</p>
			<pre><code language="javascript">
&gt; plt2.xMin = -5.0;
&gt; plt2.xMax = 5.0;
&gt; plt2.yMin = -5.0;
&gt; plt2.yMax = 5.0;</code></pre>
			<p>
				Similar to before, we will render our plot, use <code>vdom2html()</code> to generate HTML, select a DOM element into which we want to insert our plot, and then inject the rendered HTML.
			</p>
			<pre><code language="javascript">
&gt; var el2 = document.querySelector( '#scatter-plot' );
&gt; el2.innerHTML = vdom2html( plt2.render() );</code></pre>
			<figure id="scatter-plot" align="center">
				<img alt="placeholder" src="img/plot_placeholder.png" style="max-width:400px;">
				<figcaption>Figure #scatter-plot: A scatter plot.</figcaption>
			</figure>
			<p>
				The plot view should look similar to the following:
			</p>
			<figure align="center">
				<img alt="Scatter plot" src="img/scatter_plot.png" style="max-width: 600px;">
				<figcaption>Figure E2: Expected plot.</figcaption>
			</figure>
			<p>
				For our next plot, let us try plotting multiple lines. Instead of a single <code>x</code> and <code>y</code>, we will want to generate multiple datasets. Similar to before, we can generate <a title="Normal distribution" href="https://en.wikipedia.org/wiki/Normal_distribution">normally distributed</a> pseudorandom data, but this time we will use <code>base.random.normal()</code> to draw pseudorandom numbers from a <a title="Normal distribution" href="https://en.wikipedia.org/wiki/Normal_distribution">normal distribution</a> with mean <code>&mu;</code> and standard deviation <code>&sigma;</code>.
			</p>
			<pre><code language="javascript">
&gt; var x = new Int8Array( 100 );
&gt; inmap( x, function ( v, i ) { return i; } );
&gt; var y1 = new Float64Array( x.length );
&gt; var y2 = new Float64Array( x.length );
&gt; inmap( y1, function () { return base.random.normal( 50.0, 20.0 ); } );
&gt; inmap( y2, function () { return base.random.normal( 60.0, 10.0 ); } );</code></pre>
		  <p>
				In the above, we generate a single <code>x</code> vector, which can be reused when plotting against <code>y1</code> and <code>y2</code>. Now that we have data to plot, we can create a plot instance and customize accordingly, specifying properties for each data series.
		  </p>
		  <pre><code language="javascript">
&gt; var plt3 = plot( [x,x], [y1,y2] );
&gt; plt3.title = 'Multiple Lines';
&gt; plt3.lineStyle = [ '-', ':' ];
&gt; plt3.lineOpacity = [ 0.9, 0.3 ];
&gt; plt3.colors = [ 'red', 'green' ];</code></pre>
			<p>
				To plot the data, we select the placeholder DOM element and insert the rendered HTML.
			</p>
			<pre><code language="javascript">
&gt; var el3 = document.querySelector( '#multiple-line-plot' );
&gt; el3.innerHTML = vdom2html( plt3.render() );</code></pre>
			<figure id="multiple-line-plot" align="center">
				<img alt="placeholder" src="img/plot_placeholder.png" style="max-width:400px;">
				<figcaption>Figure #multiple-line-plot: A plot with multiple lines.</figcaption>
			</figure>
			<p>
				The plot view should look similar to the following:
			</p>
			<figure align="center">
				<img alt="Multiple line plot" src="img/multiple_line_plot.png" style="max-width: 600px;">
				<figcaption>Figure E3: Expected plot.</figcaption>
			</figure>
			<p>
				We can also combine plot types. For our next plot, let us combine a <a title="Line chart" href="https://en.wikipedia.org/wiki/Line_chart">line chart</a> with a <a title="Scatter plot" href="https://en.wikipedia.org/wiki/Scatter_plot">scatter plot</a>. Using the same data from the multiple line plot,
			</p>
			<pre><code language="javascript">
&gt; var plt4 = plot( [x,x], [y1,y2] );
&gt; plt4.title = 'Line + Scatter';
&gt; plt4.lineStyle = [ '-', ':' ];
&gt; plt4.symbols = [ 'closed-circle', 'open-circle' ];
&gt; var el4 = document.querySelector( '#line-scatter-plot' );
&gt; el4.innerHTML = vdom2html( plt4.render() );</code></pre>
			<figure id="line-scatter-plot" align="center">
				<img alt="placeholder" src="img/plot_placeholder.png" style="max-width:400px;">
				<figcaption>Figure #line-scatter-plot: A line chart combined with a scatter plot.</figcaption>
			</figure>
			<p>
				The plot view should look similar to the following:
			</p>
			<figure align="center">
				<img alt="Line chart and scatter plot" src="img/line_scatter_plot.png" style="max-width: 600px;">
				<figcaption>Figure E4: Expected plot.</figcaption>
			</figure>
			<p>
				As a last exercise, let us create another combination plot. This time we will combine a <a title="Scatter plot" href="https://en.wikipedia.org/wiki/Scatter_plot">scatter plot</a> with a <i>rug plot</i>. A <i>rug plot</i> provides a compact 1-dimensional visualization to supplement higher dimensional plots by displaying a <a title="Marginal distribution" href="https://en.wikipedia.org/wiki/Marginal_distribution">marginal distribution</a> along one axis.
			</p>
			<aside class="special">
				<p>
					Displaying a <a title="Marginal distribution" href="https://en.wikipedia.org/wiki/Marginal_distribution">marginal distribution</a> is useful in helping reveal the "shape" of data, especially when visual space is limited.
				</p>
			</aside>
			<p>
				Reusing the <code>y1</code> and <code>y2</code> data from above, we can proceed as follows
			</p>
			<pre><code language="javascript">
&gt; var plt5 = plot( [y1], [y2] );
&gt; plt5.title = 'Scatter + Rug';
&gt; plt5.xLabel = 'y1';
&gt; plt5.yLabel = 'y2';
&gt; plt5.lineStyle = 'none';
&gt; plt5.symbols = 'closed-circle';</code></pre>
			<p>
				To help us better compare the shapes of the two datasets, we want equal axis limits (i.e., both datasets should be plotted on the same <i>scale</i>); otherwise, we might draw incorrect conclusions when comparing the data distributions.
			</p>
			<pre><code language="javascript">
&gt; plt5.xMin = -10.0;
&gt; plt5.xMax = 110.0;
&gt; plt5.yMin = -10.0;
&gt; plt5.yMax = 110.0;</code></pre>
			<p>
				Finally, we want to display rug plots for both axes (i.e., plot <a title="Marginal distribution" href="https://en.wikipedia.org/wiki/Marginal_distribution">marginal distributions</a> for both datasets). In which case, we need to toggle the relevant plot properties.
			</p>
			<pre><code language="javascript">
&gt; plt5.xRug = true;
&gt; plt5.yRug = true;</code></pre>
			<p>
				At this point, we are ready to render! To do so, we proceed as we have done previously.
			</p>
			<pre><code language="javascript">
&gt; var el5 = document.querySelector( '#scatter-rug-plot' );
&gt; el5.innerHTML = vdom2html( plt5.render() );</code></pre>
			<figure id="scatter-rug-plot" align="center">
				<img alt="placeholder" src="img/plot_placeholder.png" style="max-width:400px;">
				<figcaption>Figure #scatter-rug-plot: A scatter plot with rug plots displayed on both axes.</figcaption>
			</figure>
			<p>
				The plot view should look similar to the following:
			</p>
			<figure align="center">
				<img alt="Scatter plot combined with rug plots" src="img/scatter_rug_plot.png" style="max-width: 600px;">
				<figcaption>Figure E5: Expected plot.</figcaption>
			</figure>
			<p>
				As you may observe, <code>y1</code> is more disperse than <code>y2</code>, which is concisely conveyed by the rug plots displayed along both axes.
			</p>

			<h3>Exercises</h3>
			<ul>
				<li>
					<p>
						Recreate the figure displayed at the beginning of this lab, plotting into the element <code>#plot-exercise-1</code> provided below.
					</p>
					<figure id="plot-exercise-1" align="center">
						<img alt="placeholder" src="img/plot_placeholder.png" style="max-width:400px;">
						<figcaption>Figure #plot-exercise-1: Plot for exercise 1.</figcaption>
					</figure>
				</li>
				<li>
					<p>
						Plot the Federal Reserve Bank wage rigidity dataset <code>FRB_SF_WAGE_RIGIDITY()</code>, using the element <code>#plot-exercise-2</code> provided below. Note that this dataset has missing data.
					</p>
					<figure id="plot-exercise-2" align="center">
						<img alt="placeholder" src="img/plot_placeholder.png" style="max-width:400px;">
						<figcaption>Figure #plot-exercise-2: Plot for exercise 2.</figcaption>
					</figure>
				</li>
			</ul>

			<h3>Survey</h3>
			<google-codelab-survey survey-id="plotting">
				<h4>How often do you plot data?</h4>
				<paper-radio-group>
					<paper-radio-button>Never</paper-radio-button>
					<paper-radio-button>Rarely</paper-radio-button>
					<paper-radio-button>Sometimes</paper-radio-button>
					<paper-radio-button>Frequently</paper-radio-button>
					<paper-radio-button>Everyday</paper-radio-button>
				</paper-radio-group>

				<h4>Did you find this lab useful?</h4>
				<paper-radio-group>
					<paper-radio-button>Not useful</paper-radio-button>
					<paper-radio-button>Somewhat useful</paper-radio-button>
					<paper-radio-button>Useful</paper-radio-button>
					<paper-radio-button>Very useful</paper-radio-button>
				</paper-radio-group>

				<h4>How do you feel about the length of this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Too short</paper-radio-button>
					<paper-radio-button>Just right</paper-radio-button>
					<paper-radio-button>Too long</paper-radio-button>
				</paper-radio-group>

				<h4>Apart from the final exercises, how difficult did you find this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Very Easy</paper-radio-button>
					<paper-radio-button>Easy</paper-radio-button>
					<paper-radio-button>Just Right</paper-radio-button>
					<paper-radio-button>Difficult</paper-radio-button>
					<paper-radio-button>Very Difficult</paper-radio-button>
				</paper-radio-group>

				<h4>How difficult did you find the exercises for this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Very Easy</paper-radio-button>
					<paper-radio-button>Easy</paper-radio-button>
					<paper-radio-button>Just Right</paper-radio-button>
					<paper-radio-button>Difficult</paper-radio-button>
					<paper-radio-button>Very Difficult</paper-radio-button>
				</paper-radio-group>

				<h4>Are you more likely to plot data after completing this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>No</paper-radio-button>
					<paper-radio-button>Maybe</paper-radio-button>
					<paper-radio-button>Yes</paper-radio-button>
				</paper-radio-group>
			</google-codelab-survey>

		</google-codelab-step>

		<!-- Statistical Distributions -->

		<google-codelab-step label="Statistical Distributions" duration="15">
			<p>
				A <a title="Probability distribution" href="https://en.wikipedia.org/wiki/Probability_distribution">probability distribution</a> is a description of the relative frequency in which each possible outcome will occur in an <strong>experiment</strong>. For example, if a random variable <code>X</code> denotes the outcome of a coin toss (the experiment), then the <a title="Probability distribution" href="https://en.wikipedia.org/wiki/Probability_distribution">probability distribution</a> of <code>X</code> is <code>0.5</code> that <code>X</code> is heads and <code>0.5</code> that <code>X</code> is tails (assuming a <i>fair</i> coin; i.e., a coin in which both sides are equally probable).
			</p>
			<p>
				The study of <a title="Probability distribution" href="https://en.wikipedia.org/wiki/Probability_distribution">probability distributions</a> is important because <a title="Probability distribution" href="https://en.wikipedia.org/wiki/Probability_distribution">probability distributions</a> allow us to concisely <a title="Statistical model" href="https://en.wikipedia.org/wiki/Statistical_model">model</a> data in mathematical terms. Once modeled, we are able to generate hypotheses, conduct statistical tests to test those hypotheses, and perform <a title="Statistical inference" href="https://en.wikipedia.org/wiki/Statistical_inference">statistical inference</a>.
			</p>
			<aside class="special">
				<p>
					<a title="Statistical inference" href="https://en.wikipedia.org/wiki/Statistical_inference">Statistical inference</a> is the process of analyzing data to deduce properties (e.g., how many times we should expect to observe a particular outcome) of the data's underlying data generating process (e.g., the act of tossing a coin). The inferred properties allow us to make statements, including predictions, regarding a <i>population</i> of which the data is assumed to be a subset. For example, if we assume that heights of males in the UK follows a <a title="Normal distribution" href="https://en.wikipedia.org/wiki/Normal_distribution">normal distribution</a>  (i.e., a bell-shaped curve) having mean <code>&mu;</code> and standard deviation <code>&sigma;</code>, we can compute the likelihood of observing a male who is 2 meters tall, even if the data serving as the basis of our model does not contain an observation having the same value.
				</p>
			</aside>
			<p>
				In the previous lab, we generated <a title="Normal distribution" href="https://en.wikipedia.org/wiki/Normal_distribution">normally distributed</a> data. In this lab, we will continue to explore this and other distributions.
			</p>

			<h3>Histograms</h3>

			<p>
				One of the most commonly used distributions for modeling data is the <a title="Normal distribution" href="https://en.wikipedia.org/wiki/Normal_distribution">normal distribution</a>. To help us better understand its properties, let us begin by generating pseudorandom numbers drawn from a <a title="Normal distribution" href="https://en.wikipedia.org/wiki/Normal_distribution">normal distribution</a> with a known mean and standard deviation.
			</p>
			<pre><code language="javascript">
&gt; var N = 100; // number of observations
&gt; var data = new Float64Array( N );
&gt; inmap( data, function () { return base.random.normal( 0.0, 1.0 ); } );</code></pre>
			<p>
				To see the shape of our data, we can construct a <a title="Histogram" href="https://en.wikipedia.org/wiki/Histogram">histogram</a>, in which we "bin" each observation and count the number of observations for each bin.
			</p>
			<aside class="special">
				<p>
					<i>Binning</i> refers to dividing a value range into a series of intervals and determining in which interval an observation falls.
				</p>
			</aside>
			<p>
				In order to place our data in bins having a width of <code>0.1</code>, we can first use the function <code>base.roundn()</code> to round each observation to a specified number of decimal places. For bin widths of <code>0.1</code>, we want to round to the first decimal.
			</p>
			<pre><code language="javascript">
&gt; inmap( data, function ( d ) { return base.roundn( d, -1 ); } );</code></pre>
			<p>
				Currently, the data array is unordered, and, if ordered, would probably contain "gaps", in which a bin (i.e., rounded value) does not have any observations and thus is not present in the array. To transform our data array into a dense representation, we can proceed as follows. First, we define the expected bin domain.
			</p>
			<pre><code language="javascript">
&gt; var bmin = -5.0;
&gt; var bmax = 5.0;</code></pre>
			<p>
				where <code>bmin</code> and <code>bmax</code> represent the leftmost bin location (center) and the rightmost bin location (center), respectively. Now that we have defined our bin domain, we can compute the number of bins as follows:
			</p>
			<pre><code language="javascript">
&gt; var bwidth = 0.1;
&gt; var nbins = ((bmax-bmin) / bwidth) + 1;</code></pre>
			<p>
				You can convince yourself of the bin formula by considering the bin vector: {0, 1, 2, 3}, where <code>0</code> and <code>3</code> are the leftmost and rightmost bin centers, respectively. If we apply the formula above, we recover the vector length, as expected.
			</p>
			<p>
				Now that we have the number of bins, we can initialize a vector which will contain the bin counts for each bin in the expected domain.
			</p>
			<pre><code language="javascript">
&gt; var counts = new Int32Array( nbins );</code></pre>
			<p>
				Next, when determining bin counts, we need to define a method which allows us to efficiently determine a value's bin index. By this we mean, if given the observation <code>-0.1</code>, what is the array index in the <code>counts</code> vector for the bin whose count we want to update? Building on the formula above for <code>nbins</code>, we can define the following function:
			</p>
			<pre><code language="javascript">
&gt; function bidx( bmin, bwidth, v ) { return base.round( base.abs(bmin-v) / bwidth ); };</code></pre>
			<aside class="special">
				<p>
					Why does the index formula use <code>base.round()</code>? Try implementing the index formula without rounding and provide <code>v = -2.1</code>.
				</p>
			</aside>
			<p>
				To convince yourself of the index formula, consider the edge cases <code>-5.0</code> and <code>5.0</code>. If <code>v = -5.0</code>, the computed index is <code>0</code>, which corresponds to the leftmost bin. If <code>v = 5.0</code>, the computed index is <code>100</code>, which corresponds to the rightmost bin. As an exercise, compute the indexes for <code>-4.8</code> and <code>4.8</code> and confirm that the returned index is correct.
			</p>
			<aside class="special">
				<p>
					The index formula does <strong>not</strong> address data values which are outside the expected domain. How should we handle these values?
				</p>
			</aside>
			<p>
				Now that we have a means for computing a bin index, we can populate our <code>counts</code> vector by iterating over our <code>data</code> array and updating the corresponding count.
			</p>
			<pre><code language="javascript">
&gt; var idx, i;
&gt; for ( i = 0; i &lt; data.length; i++ ) {
    idx = bidx( bmin, bwidth, data[ i ] );
    counts[ idx ] += 1;
};</code></pre>
			<p>
				In order to plot the data, we need to construct a bin vector, which will be plotted along the x-axis, covering the expected bin domain; i.e., -5.0, -4.9, ..., 4.9, 5.0.
			</p>
			<pre><code language="javascript">
&gt; var bcenters = new Float64Array( nbins );
&gt; var bc;
&gt; for ( i = 0; i &lt; nbins; i++ ) {
    bc = bmin + (bwidth*i);
    bcenters[ i ] = base.roundn( bc, -1 );
};</code></pre>
			<p>
				To plot the data, we proceed as we did in the previous lab.
			</p>
			<pre><code language="javascript">
&gt; var plt1 = plot( [bcenters], [counts] );
&gt; plt1.xLabel = 'x';
&gt; plt1.yLabel = 'counts';
&gt; var el = document.querySelector( '#histogram-normal-1' );
&gt; el.innerHTML = vdom2html( plt1.render() );</code></pre>
			<figure id="histogram-normal-1" align="center">
				<img alt="placeholder" src="img/plot_placeholder.png" style="max-width:400px;">
				<figcaption>Figure #histogram-normal-1: A histogram of numbers drawn from a normal distribution.</figcaption>
			</figure>
			<p>
				The plot view should look similar to the following:
			</p>
			<figure align="center">
				<img alt="A histogram of numbers drawn from a normal distribution" src="img/histogram_normal_1.png" style="max-width: 600px;">
				<figcaption>Figure E6: Expected plot.</figcaption>
			</figure>
			<p>
				To see how well the empirical distribution matches the expected distribution, let us first generate an (approximated) expected distribution using <code>base.dist.normal.pdf()</code>.
			</p>
			<pre><code language="javascript">
&gt; var expected = new Float64Array( bcenters.length );
&gt; forEach( bcenters, function ( x, i ) {
    var density = base.dist.normal.pdf( x, 0.0, 1.0 );
    expected[ i ] = N * bwidth * density;
});</code></pre>
			<aside class="special">
				<p>
					The conversion from a probability density to a probability is more involved than the <a title="Approximating a probability from a probability density" href="http://mathinsight.org/probability_density_function_idea">approximation</a> used here.
				</p>
			</aside>
			<p>
				We can now update the plot to show both the empirical and expected distributions.
			</p>
			<pre><code language="javascript">
&gt; var plt2 = plot( [bcenters,bcenters], [counts,expected] );
&gt; plt2.xLabel = 'x';
&gt; plt2.yLabel = 'counts';
&gt; var el = document.querySelector( '#histogram-normal-overlay-1' );
&gt; el.innerHTML = vdom2html( plt2.render() );</code></pre>
			<figure id="histogram-normal-overlay-1" align="center">
				<img alt="placeholder" src="img/plot_placeholder.png" style="max-width:400px;">
				<figcaption>Figure #histogram-normal-overlay-1: Empirical and expected distributions.</figcaption>
			</figure>
			<p>
				The plot view should look similar to the following:
			</p>
			<figure align="center">
				<img alt="Empirical and expected distributions" src="img/histogram_normal_overlay_1.png" style="max-width: 600px;">
				<figcaption>Figure E7: Expected plot.</figcaption>
			</figure>
			<p>
				How well do you think the empirical distribution resembles the expected distribution? How would you explain discrepancies between the empirical and expected distributions?

			<h3>Exercises</h3>
			<ul>
				<li>
					<p>
						Based on the approached outlined above, create a function for generating a histogram from an input data array. The function should have the following signature:
					<p>
					<pre><code language="javascript">
hist( data, bmin, bmax, bwidth )</code></pre>
					<p>
						Test your function by plotting into the element <code>#histogram-exercise-1</code> provided below.
					</p>
					<figure id="histogram-exercise-1" align="center">
						<img alt="placeholder" src="img/plot_placeholder.png" style="max-width:400px;">
						<figcaption>Figure #histogram-exercise-1: Plot for exercise 1.</figcaption>
					</figure>
				</li>
				<li>
					<p>Repeat the generation of the empirical and expected distribution, but increase the number of observations. Insert your plot into the element <code>#histogram-exercise-2</code> provided below.
					</p>
					<figure id="histogram-exercise-2" align="center">
						<img alt="placeholder" src="img/plot_placeholder.png" style="max-width:400px;">
						<figcaption>Figure #histogram-exercise-2: Plot(s) for exercise 2.</figcaption>
					</figure>
				</li>
				<li>
					<p>
						Investigate other distributions; e.g.,
					</p>
					<pre><code>
base.random.beta()
base.dist.beta.pdf()

base.random.laplace()
base.dist.laplace.pdf()

base.random.exponential()
base.dist.exponential.pdf()</code></pre>
					<p>
						Insert your plots into the element <code>#histogram-exercise-3</code> provided below.
					</p>
					<figure id="histogram-exercise-3" align="center">
						<img alt="placeholder" src="img/plot_placeholder.png" style="max-width:400px;">
						<figcaption>Figure #histogram-exercise-3: Plot for exercise 3.</figcaption>
					</figure>
				</li>
			</ul>

			<h3>Survey</h3>
			<google-codelab-survey survey-id="statistical-distributions">
				<h4>Did you find this lab useful?</h4>
				<paper-radio-group>
					<paper-radio-button>Not useful</paper-radio-button>
					<paper-radio-button>Somewhat useful</paper-radio-button>
					<paper-radio-button>Useful</paper-radio-button>
					<paper-radio-button>Very useful</paper-radio-button>
				</paper-radio-group>

				<h4>How do you feel about the length of this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Too short</paper-radio-button>
					<paper-radio-button>Just right</paper-radio-button>
					<paper-radio-button>Too long</paper-radio-button>
				</paper-radio-group>

				<h4>Apart from the final exercises, how difficult did you find this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Very Easy</paper-radio-button>
					<paper-radio-button>Easy</paper-radio-button>
					<paper-radio-button>Just Right</paper-radio-button>
					<paper-radio-button>Difficult</paper-radio-button>
					<paper-radio-button>Very Difficult</paper-radio-button>
				</paper-radio-group>

				<h4>How difficult did you find the exercises for this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Very Easy</paper-radio-button>
					<paper-radio-button>Easy</paper-radio-button>
					<paper-radio-button>Just Right</paper-radio-button>
					<paper-radio-button>Difficult</paper-radio-button>
					<paper-radio-button>Very Difficult</paper-radio-button>
				</paper-radio-group>
			</google-codelab-survey>

		</google-codelab-step>

		<!-- Statistical Tests -->

		<google-codelab-step label="Statistical Tests" duration="20">
			<p>
				Comparing an outcome between two (or more) groups is a very common statistical task. <a title="Statistical hypothesis testing" href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">Hypothesis tests</a> help us to assess whether a difference is <i>statistically significant</i>.
			</p>
			<aside class="special">
				<p>
					Loosely speaking, by <i>statistically significant</i> we mean whether an observation has a high likelihood of being due to a systematic difference between the two (or more) groups and a low likelihood of occurring by chance alone.
				</p>
			</aside>
			<p>
				Imagine the following scenario: you have two landing pages for your website and would like to know which one is more effective in converting visitors. Suppose you have collected the following two data sets, where a <code>1</code> denotes that a visitor signed up and a <code>0</code> denotes that a visitor left the page without taking any action.
			</p>
			<pre><code language="javascript">
&gt; var page1 = [
    1, 0, 0, 0, 0, 0, 1, 0, 0, 1,
    0, 0, 0, 1, 0, 0, 0, 1, 0, 0,
    0, 1, 1, 0, 0, 0, 0, 0, 0, 0
];
&gt; var page2 = [
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 1, 0, 0
];</code></pre>
			<p>
				A cursory look at the data suggests that the first page is more effective at converting users. To be a bit more quantitative, let us calculate the proportion of users (<i>mean</i>) who signed up per page using the <code>reduce()</code> function.
			</p>
			<pre><code language="javascript">
&gt; function sum( acc, v ) { return acc + v; };
&gt; var sum1 = reduce( page1, 0, sum )
7
&gt; var sum2 = reduce( page2, 0, sum )
2
&gt; var mu1 = sum1 / page1.length
0.23333333333333334
&gt; var mu2 = sum2 / page2.length
0.06666666666666667</code></pre>
			<p>
				Pretty striking difference, right?
			</p>
			<aside class="special">
				<p>
					When you have a binary variable made up of zeros and ones, calculating the mean gives you the proportion of observations which are in the <code>1</code> category. This is the <strong>only</strong> instance in which calculating a numerical <a href="https://en.wikipedia.org/wiki/Summary_statistics">summary statistic</a> for <a href="https://en.wikipedia.org/wiki/Categorical_variable">categorical data</a> is appropriate.
				</p>
			</aside>
			<p>
				While the difference in means seems large, is the difference also statistically significant? Let us find out!
			</p>
			<aside class="special">
				<p>
					Often, the most difficult part of conducting statistical tests is knowing what test to use and how to interpret results. Fortunately, <a title="A standard library for Node.js and JavaScript" href="https://github.com/stdlib-js/stdlib">stdlib</a> statistical tests return extensive result summaries, facilitating interpretation and helping you to assess the test result.
				</p>
			</aside>
			<p>
				To test for statistical significance, we can use <code>ttest2()</code> command.
			</p>
			<pre><code language="javascript">
&gt; var out = ttest2( page1, page2 )</code></pre>
			<p>
				The returned test result has a <code>rejected</code> property which is a boolean indicating whether the null hypothesis of the test was rejected. The <strong>null hypothesis</strong>, which is often denoted <i>H0</i>, denotes the case where a difference is not statistically significant. The <strong>alternative hypothesis</strong>, which is often denoted <i>H1</i>, denotes the case where a difference is statistically significant.
			</p>
			<p>
				For pretty-printed output, use the <code>out.print()</code> method, which will print the exact definition of the alternative hypothesis.
			</p>
			<pre><code language="javascript">
&gt; out.print()</code></pre>
			<p>
				Based on the test results, do we conclude that the first page or the second page is more effective at converting visitors?
			</p>
			<p>
				Observe that the test decision has an inherent uncertainty; i.e., a small probability exists that you might have reached a false conclusion. How large is this probability?
			</p>
			<p>
				When all test assumptions are satisfied, the significance level of a test, commonly denoted by the Greek letter <code>&alpha;</code>, informs you as to the probability that you reject the null hypothesis even though the null hypothesis is true. Hypothesis testing gives us <strong>only</strong> this guarantee and does <strong>not</strong> provide any guarantees when we fail to reject a false null hypothesis.
			</p>
			<aside class="special">
				<p>
					By default, <code>ttest2()</code> and the other <a title="A standard library for Node.js and JavaScript" href="https://github.com/stdlib-js/stdlib">stdlib</a> statistical tests test for a non-directional effect. This is called a <i>two-sided</i> test. When you have prior beliefs about which group has a larger effect, consider running a <i>one-sided</i> test by setting the <code>alternative</code> option of the test. For illustration purposes, rerun the test for the landing pages using one-sided tests and observe how the alternative hypothesis and test result change. Keep in mind, however, that you should choose a test direction <strong>before</strong> looking at the data.
				</p>
			</aside>

			<h3>Simulation Study</h3>
			<p>
				We can decide whether a null hypothesis should be rejected by using the <a title="p-value" href="https://en.wikipedia.org/wiki/P-value">p-value</a> of a statistical test. A smaller p-value indicates that a hypothesis fails to adequately explain the data. As a decision rule, we reject the hypothesis whenever the <a title="p-value" href="https://en.wikipedia.org/wiki/P-value">p-value</a> is lower than the chosen significance level <code>&alpha;</code>, which, by convention, is often set to <code>0.05</code>.
			</p>
			<p>
				Recall that <code>&alpha;</code> denotes the probability that you reject the null hypothesis even though the hypothesis is true. By fixing <code>&alpha;</code> at <code>0.05</code>, we are basically saying that we are content with erroneously rejecting the null hypothesis in 5% of the cases.
			</p>
			<p>
				Why is <code>&alpha;</code> equal to this error probability? We can mathematically prove that, if the null hypothesis is true, then the <a title="p-value" href="https://en.wikipedia.org/wiki/P-value">p-value</a> follows a <a title="Uniform distribution" href="https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)">uniform distribution</a> on the interval <code>[0,1]</code>. Hence, over the course of many experiments, we would expect 5% of p-values to be smaller than <code>0.05</code>. Instead of a mathematical proof, let us simulate some data to confirm that this is indeed the case.
			</p>
			<p>
				We will consider the hypothesis that the true mean of a distribution from which we observe data is equal to zero. For this purpose, we may use the <code>ttest</code> function, which can perform a one-sample <a title="Student's t-test" href="https://en.wikipedia.org/wiki/Student%27s_t-test">t-test</a>. We will generate data from a <a title="Normal distribution" href="https://en.wikipedia.org/wiki/Normal_distribution">normal distribution</a> with zero mean and some known standard deviation <code>&sigma;</code> (e.g., <code>&sigma; = 3</code>):
			</p>
			<pre><code language="javascript">
&gt; var arr = new Array( 300 );
&gt; inmap( arr, function () { return base.random.normal( 0.0, 3.0 ); } );</code></pre>
			<p>
				We then run the <a title="Student's t-test" href="https://en.wikipedia.org/wiki/Student%27s_t-test">t-test</a> and extract the p-value. To be able to repeat this process many times, let us wrap everything inside a function:
			</p>
			<pre><code language="javascript">
&gt; function simulate( size ) {
    var arr = new Array( size );
    inmap( arr, function () { return base.random.normal( 0.0, 3.0 ); } );
    var out = ttest( arr );
    return out.pValue;
}</code></pre>
			<p>
				Now create a sufficiently large array (at least a few hunded observations) and populate it with p-values generated from this function, say, for <code>size = 100</code>. Calculate the proportion of array elements that are smaller than <code>0.05</code>. Is this proportion reasonably close to <code>0.05</code>, as we would expect? Repeat the whole process a few times to see how the results vary.
			</p>
			<p>
				To formally test whether the generated p-values are drawn from a <a title="Uniform distribution" href="https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)">uniform distribution</a> between zero and one, we can use the <a href="https://en.wikipedia.org/wiki/Kolmogorov–Smirnov_test">Kolmogorov-Smirnov test</a>, a test which can be used more generally whenever one wants to test a sample against a continuous reference distribution. In <a title="A standard library for Node.js and JavaScript" href="https://github.com/stdlib-js/stdlib">stdlib</a>, the <a href="https://en.wikipedia.org/wiki/Kolmogorov–Smirnov_test">Kolmogorov-Smirnov test</a> is implemented as <code>kstest()</code>. Make yourself familiar with its usage <code>help( kstest )</code> and then use it to assess our claim.
			</p>
			<aside class="special">
				<p>
					Hint: the <code>kstest()</code> examples demonstrate how to test against a <a title="Uniform distribution" href="https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)">Uniform(0,1)</a> distribution.
				</p>
			</aside>
			<p>
				The <a title="Student's t-test" href="https://en.wikipedia.org/wiki/Student%27s_t-test">t-test</a> is based on the assumption that data originates from a <a title="Normal distribution" href="https://en.wikipedia.org/wiki/Normal_distribution">normal distribution</a>. If this assumption is violated, <a title="Student's t-test" href="https://en.wikipedia.org/wiki/Student%27s_t-test">t-test</a> results may not be trusted under certain circumstances. We will explore this issue in the exercises.
			</p>

			<h3>Exercises</h3>
			<ul>
				<li>
					<p>
						Write a new <code>simulate()</code> function for using the <a title="Student's t-test" href="https://en.wikipedia.org/wiki/Student%27s_t-test">t-test</a> when the data is generated from a <code>Gamma(1,2)</code> distribution.
					</p>
					<pre><code language="javascript">
base.random.gamma()</code></pre>
					<p>
						Instead of testing against a mean of zero, use the <code>mu</code> option of <code>ttest()</code> to test against the correct mean.
					</p>
					<p>
						Repeat this for different values of <code>size</code> and verify that the <a title="Student's t-test" href="https://en.wikipedia.org/wiki/Student%27s_t-test">t-test</a> breaks down when one has a skewed distribution such as the <code>Gamma(1,2)</code> and only small sample sizes.
					</p>
				</li>
				<li>
					<p>
						Instead of using the <i>p-value</i> to conduct one's tests, one can alternatively look at a confidence interval for the parameter of interest. Confidence intervals are often used to convey uncertainty in model estimates, since they are useful even when one does not have a concrete hypothesis one wishes to test.
					</p>
					<p>
						For a </code>1-&alpha;</code> confidence interval, one has the guarantee that, for a large number of such confidence intervals, </code>1-&alpha;</code> of them will contain the true parameter. Verify this behavior by repeatedly simulating data from a <a title="Normal distribution" href="https://en.wikipedia.org/wiki/Normal_distribution">normal distribution</a> with zero mean, extracting the confidence intervals from a <a title="Student's t-test" href="https://en.wikipedia.org/wiki/Student%27s_t-test">t-test</a>, and showing that they contain zero around </code>1-&alpha;</code> of the cases.
					</p>
					<p>
						Notice that, while in reality we are not going to repeat a specific test multiple times, we will likely conduct many different tests over a long period of time. If we conduct them all at a significance level </code>&alpha;</code>, we can be certain that </code>1-&alpha;</code> of the them contain the true value (provided all test assumptions are valid).
					</p>
				</li>
			</ul>

			<h3>Survey</h3>
			<google-codelab-survey survey-id="statistical-tests">
				<h4>Did you find this lab useful?</h4>
				<paper-radio-group>
					<paper-radio-button>Not useful</paper-radio-button>
					<paper-radio-button>Somewhat useful</paper-radio-button>
					<paper-radio-button>Useful</paper-radio-button>
					<paper-radio-button>Very useful</paper-radio-button>
				</paper-radio-group>

				<h4>How do you feel about the length of this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Too short</paper-radio-button>
					<paper-radio-button>Just right</paper-radio-button>
					<paper-radio-button>Too long</paper-radio-button>
				</paper-radio-group>

				<h4>Apart from the final exercises, how difficult did you find this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Very Easy</paper-radio-button>
					<paper-radio-button>Easy</paper-radio-button>
					<paper-radio-button>Just Right</paper-radio-button>
					<paper-radio-button>Difficult</paper-radio-button>
					<paper-radio-button>Very Difficult</paper-radio-button>
				</paper-radio-group>

				<h4>How difficult did you find the exercises for this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Very Easy</paper-radio-button>
					<paper-radio-button>Easy</paper-radio-button>
					<paper-radio-button>Just Right</paper-radio-button>
					<paper-radio-button>Difficult</paper-radio-button>
					<paper-radio-button>Very Difficult</paper-radio-button>
				</paper-radio-group>
			</google-codelab-survey>
		</google-codelab-step>

		<!-- Spam Classifier -->

		<google-codelab-step label="Spam Classifier" duration="20">
			<p>
				We are all plagued by the spam emails that arrive in our mailboxes each day. Flagging emails as spam is what we call a classification task, since it consists of assigning an observation into either of several categories (spam/no spam). In this lab, we will explore building our own spam classifier using a simple but well-performing statistical technique called <i>Naive Bayes</i>.
			</p>
			<p>
				For this purpose, we will make use of the <code>SPAM_ASSASSIN</code> data set that ships with <a title="A standard library for Node.js and JavaScript" href="https://github.com/stdlib-js/stdlib">stdlib</a>. We can load a copy of it and assign it to the variable <code>spam</code> as follows:
			</p>
				<pre><code language="javascript">
&gt; var spam = datasets( 'SPAM_ASSASSIN' );</code></pre>
			<p>
				Take a few minutes to familiarize yourself with the data set (you might also want to read its documentation).
			</p>
			<p> For this lab, the emails from the <code>easy-ham-1</code> and <code>spam-2</code> batches will serve as our training set, from which we will build a model that can then predict whether a new email should be classified as spam. To evaluate the performance of a statistical model, it is common practice to set aside a <i>test set</i> of observations for which we know the true class, but which we hold out and do not use while building our model. This ensures that we get an unbiased estimate of how well the model will generalize once we evaluate it on our test set. Here, the emails from <code>spam-1</code>, <code>hard-ham-1</code>, and <code>easy-ham-2</code> will constitute our test set.
			</p>
			<p>
			Let's store all observations belonging to the training set in a new array, as follows:
			</p>
			<pre><code language="javascript">
&gt; var training = []
&gt; for ( var i = 0; i &lt; spam.length; i++ ) {
    if ( spam[i].group === 'easy-ham-1' || spam[i].group === 'spam-2' ) {
        training.push( spam[i] );
    }
}</code></pre>
			<p>
				When you looked at some of the emails, you will have noticed that these always include meta-information of the emails before the actual content. The following function helps us to strip off this part and also removes other unwanted character sequences from the emails:
			</p>
			<pre><code language="javascript">
&gt; function extractBody( email ) {
    // Remove the meta-information before two initial line breaks:
    var LINE_BREAK_REGEXP = /[\r\n]{2}([\s\S]*)$/;
    var text = email.match( LINE_BREAK_REGEXP )[ 1 ];
    // Turn to lowercase such that a word is treated the same no matter its case:
    text = lowercase( text );
    // Expand contractions, e.g. don't => do not:
    text = expandContractions( text );
    text = removePunctuation( text );
    // Remove numbers and other special characters:
    text = text.replace( /[0-9\-\+]/g, '' );
    // Remove common words such as "the" or "and":
    text = removeWords( text, STOPWORDS );
    return text;
}</code></pre>
			<p>
				Before we are able to call this function, we need to load the list of stopwords that will be removed. Since our texts are in English, we will load a list of commonly used English words, but <a title="A standard library for Node.js and JavaScript" href="https://github.com/stdlib-js/stdlib">stdlib</a> comes with stopword lists for many other languages as well.
			</p>
			<pre><code language="javascript">
&gt; var STOPWORDS = datasets( 'STOPWORDS_EN' ); </code></pre>
			<aside class="special">
				<p>
					Very common words that do not carry significant informational value are often removed when building a bag-of-words representation. These are referred to as <i>stop words</i>. This practice was more common in the past, where memory considerations played a larger role, but the results of quite a few statistical models also benefit from the removal of such common words.
				</p>
			</aside>
			<p>
				You should now be able to call <code>extractBody()</code> on any of the spam texts. For example, try <code>extractBody( spam[ 0 ].text )</code> to look at the transformed text for the first mail. A large part of building a statistical model is the selection of variables that are useful in predicting the outcome of interest. In our case, we will just use the words appearing in the texts, but observe that we may throw away useful information by doing so. For example, we might speculate that spam mails contain more capitalized or uppercased words in order to grab the attention of the recipients.
			</p>
			<p>
				Our <i>Naive Bayes</i> model relies on a so-called <a href="https://en.wikipedia.org/wiki/Bag-of-words_model">bag-of-words</a> representation of the documents in our data set. To generate this representation, we will tokenize our texts, i.e. split them up into pieces (the so called <i>tokens</i>).
			</p>
			<aside class="special">
				<p>
					In natural language processing, a bag-of-words model is a simplifying representation of a text document, which disregards word order and grammer, only keeping count of how often a word appears in the respective document.
				</p>
			</aside>
			<p>
				We can use the <code>tokenize</code> function for this task. With these functions equipped, let us now extract the tokens for the texts in our training set, using <code>inmap()</code> to perform an in-place map operation.
			</p>
			<pre><code language="javascript">
&gt; training = inmap( training, function( x ) {
    x.body = extractBody( x.text );
    x.tokens = tokenize( x.body );
    return x;
});</code></pre>
			<aside class="special">
				<h3>Mathematical Formulation of the Naive Bayes Model</h3>
				<p>
					Naive Bayes is a classification algorithm that allows us to estimate the conditional probability that an observation belongs to a certain class given a set of features <b>x</b>. When used for modeling text documents, their words are usually used as features, but this is by no means a requirement. The model derives its name from the use of <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes' Rule</a> and the fact that is based on the "naive" assumption that the presence of any feature does not influence the probabilities of observing any other feature, i.e. the probability of observing an observation's features given class <i>c</i>, <span class="tex" data-eqn="P(\mathbf{x}|c)" ></span>, can be factorized as the product over all the individual feature probabilities. In our case, we may write this as <span class="tex" data-eqn="P(\mathbf{x}|c) = \prod_w P(w|c)" ></span>, where the product is taken over all words in the respective document.
					<a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes' Rule</a> lets us then switch the conditioning and calculate the class probabilities given the observed features:
				</p>
					<div class="tex" data-eqn="P(c|\mathbf{x}) = \frac{P(\mathbf{x}|c) P(c)}{P(\mathbf{x})}"
					displayMode></div>
				<p>
					Our decision rule of whether an email should be classified as spam is then quite simple: We can drop the denominator and calculate <span class="tex" data-eqn="P(\mathbf{x}|c) P(c) =  \prod_w P(w|c) P(c)"></span> for each class, assigning the observation to the class for which the conditional probability is larger. How do we obtain these probabilities? We estimate them by their empirical frequencies: We replace <span class="tex" data-eqn="P(c)"></span> by the percentage of documents from the respective class in our data corpus, and <span class="tex" data-eqn="P(w|c)"></span> by its relative frequency, i.e. the number of times the word appeared in documents of class <i>c</i> divided by the overall number of tokens in that class.
				</p>
			</aside>
			<p>
				Before building our model, let us explore the frequency differences for the tokens in both the spam and non-spam groups and find which ones help in discriminating between the two classes. For this purpose, we will divide our training data into two parts, and then lump the tokens from all their documents together into a single array, which we can then count to obtain the frequencies of the tokens in each group. We can use the <code>groupBy</code> function to group our training data into the two groups as follows:
			</p>
			<pre><code language="javascript">
&gt; var grouped = groupBy( training, function( x ) {
    if ( x.group === 'spam-2' ) {
        return 'spam';
    }
    return 'nospam';
});</code></pre>
			<p>
				We can now lump all tokens from texts belonging to either group together, for example by using the following code:
			<p>
			<pre><code language="javascript">
&gt; var spamTokens = pluck( grouped.spam, 'tokens' );
&gt; spamTokens = flattenArray( spamTokens );
&gt; var nospamTokens = pluck( grouped.nospam, 'tokens' );
&gt; nospamTokens = flattenArray( nospamTokens )</code></pre>
			<p>
				Let us use the <code>countBy</code> function to calculate the frequencies. Notice that we supply the <code>identity</code> function as the second argument since we want to group the array elements by their actual values.
			</p>
			<pre><code language="javascript">
&gt; var spamFreqs = countBy( spamTokens, identity );
&gt; var nospamFreqs = countBy( nospamTokens, identity );</code></pre>
			<p>
				With this convenient representation in hand, we can explore the <i>absolute frequencies</i> of the tokens in the two groups. Think of a few words that you would expect to show up much more frequently in spam mails, and check whether the frequencies support this hypothesis.
			</p>
			<p>
				However, notice that the absolute frequencies might be misleading since the groups are not equally represented in our training set, with <code>spam-2</code> containing <code>1396</code> and <code>easy-ham-1</code> containing <code>2500</code> observations. Hence, it makes more sense to look at <i>relative frequencies</i>, which take the different group sizes into account. For future reference, let us first store the relative group frequencies in an <code>object</code>:
			</p>
			<pre><code language="javascript">
&gt; var groupProbs = {
    'spam': 1396 / ( 1396 + 2500 ),
    'nospam': 2500 / ( 1396 + 2500 )
};</code></pre>
			<p>
				To turn the token counts into relative frequencies, we have to divide them by the total number of tokens in the respective group. Let us define two functions for this purpose:
			</p>
			<pre><code language="javascript">
&gt; function wordSpamProb( word ) {
    return spamFreqs[ word ] / spamTokens.length;
}
&gt; function wordNospamProb( word ) {
    return nospamFreqs[ word ] / nospamTokens.length;
}</code></pre>
			<p>
				Invoke the functions for the words you have looked at before. Now think about what would happen if we were to call either function for a word that did not occur in the respective group? For our classifier to work for documents which contain words unknown to our corpus, we will have to change the way how we estimate the different word probabilities. We will make use of a technique called <i>Laplace Smoothing</i>, which in its simplest form just consists of adding a count of one to all words, even those which do not appear in documents of a given class. With the number of unique tokens in our training data set being equal to 76,709, we can adapt the functions as follows:
			</p>
			<pre><code language="javascript">
&gt; var vocabSize = 76709;
&gt; function wordSpamProb( word ) {
    var nk = spamFreqs[ word ] || 0;
    return ( nk + 1 ) / ( spamTokens.length + vocabSize );
}
&gt; function wordNospamProb( word ) {
    var nk = nospamFreqs[ word ] || 0;
    return ( nk + 1 ) / ( nospamTokens.length + vocabSize );
}</code></pre>
			<aside class="special">
				<h3>Laplace Smoothing</h3>
				<p>
					Estimating the word probabilities <span class="tex" data-eqn="P(w|c)"></span> by the empirical frequencies is problematic because it would mean that for any word not appearing in any of the documents of the respective class, we would estimate is as zero. However, this would imply that when classifying a new document containing a word not present in the documents of a given class, it would get assigned a probability of zero, even though it may otherwise might look a lot like the documents from said class. To deal with this issue, one could simply drop words that are unknown to the training corpus, but a better approach is <i>Laplace Smoothing</i>, in which a non-zero probability is assigned to every word beforehand. This is achieved by adding a value <span class="tex" data-eqn="\alpha"></span> to any count, so that the probability estimates change from
				</p>
				<div class="tex" data-eqn="\hat P(w|c) = \frac{count(w,c)}{\sum_{w \text{ in } V} count(w,c) } = \frac{count(w,c)}{N_c}" displayMode></div>
				<p>to</p>
				<div class="tex" data-eqn="\hat P(w|c) = \frac{count(w,c)}{\sum_{w \text{ in } V} count(w,c) }= \frac{count(w,c) + \alpha}{N_c+\alpha|V|}" displayMode></div>
				</p>
				where <span class="tex" data-eqn="count(w,c)"></span> is the number of times word <i>w</i> appears in the documents of class <i>c</i>, <span class="tex" data-eqn="N_c"></span> is its total number of tokens, and <span class="tex" data-eqn="|V|"></span> is the overall size of the vocabulary. Often, <span class="tex" data-eqn="\alpha"></span> is chosen to be one. <i>Laplace Smoothing</i> is preferable compared to simply discarding unknown tokens because these should decrease the probability of belonging to the respective class; they should just not turn it to zero.
			</aside>
			<p>
				Our workhorse function to classify new emails can now be implemented in a relatively straightforward manner. Instead of directly evaluating <span class="tex" data-eqn="\prod_w P(w|c)"></span>, which is prone to underflow issues since many of the probabilities will be small, we will take the natural logarithm and calculate the sum <span class="tex" data-eqn="\sum_w \ln P(w|c)"></span> instead. Taking the logarithm is a monotonic transformation, which does not change the rank order of the untransformed values. Therefore, predictions made from the model are not affected by this choice.
			</p>
			<pre><code language="javascript">
&gt; function classifyEmail( text ) {
    var body = getBody( text );
    var tokens = tokenize( body );
    var spamScore = base.ln( classProbs[ "spam" ] );
    for ( let i = 0; i &lt; tokens.length; i++ ) {
        spamScore += base.ln( wordSpamProb( tokens[i] ) );
    }
    var nospamScore = base.ln( classProbs[ "nospam" ] );
    for ( let i = 0; i &lt; tokens.length; i++ ) {
        nospamScore += base.ln( wordNospamProb( tokens[i] ) );
    }
    return spamScore &gt; nospamScore ? 'spam' : 'nospam';
}</code></pre>
			<p>
				Test the function out on a few of the emails from <code>spam</code>. Do we make the correct predictions?
			</p>

			<h3>Exercises</h3>
			<ul>
				<li>Let us assess the performance of our model by creating a table of the percentages of emails that are correctly classified in each of the groups (from both the training and test sets). What do you observe?</li>
				<li>Can you think of some other features besides the words that could discriminate between the classes? Think about stuff like the number of capitalized words or $ signs. Check whether your assumption is correct and there is a difference in their frequency among the spam and non-spam mails. The process of identifying and creating new variables that are predtictive of the outcome is often called <i>feature engineering</i>. Notice that the <i>Naive Bayes</i> classifier is not restricted to words, but could use all these other features as well!</li>
			</ul>

			<h3>Survey</h3>
			<google-codelab-survey survey-id="spam-classifier">
				<h4>Did you find this lab useful?</h4>
				<paper-radio-group>
					<paper-radio-button>Not useful</paper-radio-button>
					<paper-radio-button>Somewhat useful</paper-radio-button>
					<paper-radio-button>Useful</paper-radio-button>
					<paper-radio-button>Very useful</paper-radio-button>
				</paper-radio-group>

				<h4>How do you feel about the length of this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Too short</paper-radio-button>
					<paper-radio-button>Just right</paper-radio-button>
					<paper-radio-button>Too long</paper-radio-button>
				</paper-radio-group>

				<h4>Apart from the final exercises, how difficult did you find this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Very Easy</paper-radio-button>
					<paper-radio-button>Easy</paper-radio-button>
					<paper-radio-button>Just Right</paper-radio-button>
					<paper-radio-button>Difficult</paper-radio-button>
					<paper-radio-button>Very Difficult</paper-radio-button>
				</paper-radio-group>

				<h4>How difficult did you find the exercises for this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Very Easy</paper-radio-button>
					<paper-radio-button>Easy</paper-radio-button>
					<paper-radio-button>Just Right</paper-radio-button>
					<paper-radio-button>Difficult</paper-radio-button>
					<paper-radio-button>Very Difficult</paper-radio-button>
				</paper-radio-group>
			</google-codelab-survey>

		</google-codelab-step>

		<!-- KDEs and Clustering -->

		<google-codelab-step label="KDEs and Clustering" duration="20">
			<h3>Kernel Density Estimation (KDE)</h3>
			<p>
				Over the course of this workshop, we got to know several known statistical distributions and how to work with them. Now imagine that you have some observations from an unknown distribution and would like to estimate the distribution they are coming from, for example as part of a machine learning algorithm. If you can make some distributional assumption, e.g. that the data are generated from a normal distribution, then the problem reduces to estimating the parameters of the distribution, which is usually done via the <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">maximum likelihood</a> method.
			</p>
			<p>
				As a running example, consider the case where we have data drawn from the following distribution:
			</p>
			<figure id="bimodal" align="center">
				<img alt="Density of a bimodal distribution" src="img/bimodal.png" style="max-width: 600px;">
			</figure>
			<p>
				To estimate such distributions without making any strong parametric assumptions, one can use a class of models called kernel density estimators (KDEs). In contrast to a parametric model, where we encode all information on the distribution in their parameters, KDEs are non-parametric and use all data points to form an estimate for a given input value. Since they can learn the  shape of  the  density  from the  data  automatically, they are very flexible and can even learn complicated distributions. To see how this works, let us imagine we some data drawn from above distribution. The density function for above distribution was
			</p>
			<pre><code language="javascript">
&gt; var truePDF = function( x ) {
    return 0.5 * base.dist.normal.pdf( x, 2, 1 ) + 0.5 * base.dist.normal.pdf( x, 9, 2 );
}</code></pre>
			<p> and we can draw a sample from it as follows: </p>
			<pre><code language="javascript">
&gt; var xs = new Array( 100);
&gt; inmap( xs, function() { return base.random.randu() > 0.5 ? base.random.normal( 2, 1) : base.random.normal( 9, 2); } );</code></pre>
			<p>
				The kernel density estimator for an unknown <a href="https://en.wikipedia.org/wiki/Probability_density_function">density</a> is defined as
			</p>
			<span class="tex" data-eqn="\displaystyle {\hat {f}}_{h}(x)={\frac {1}{nh}}\sum _{i=1}^{n}K{\Big (}{\frac {x-x_{i}}{h}}{\Big )}," displayMode></span>
			<p>
				where <i>n</i> is the number observations, <i>K</i> is a so-called <a href="https://en.wikipedia.org/wiki/Kernel_(statistics)">kernel function</a>, and <i>h</i> the bandwidth.
			</p>
			<p>
				We can implement the kernel density estimator as follows:
			</p>
			<pre><code language="javascript">
&gt; function fhat( x, xs, K, h ) {
    var out = 0;
    var n = xs.length;
    for ( var i = 0; i &lt; n; i++ ) {
        out += K( ( x - xs[i] ) / h );
    }
    return out / ( n*h );
}</code></pre>
			<p>
				To gain some intuition into how KDEs work, the next figure shows a kernel density constructed from the six data points located at the black rugs. The KDE works by smoothing each of these observations into a bump (displayed as the dashed red lines), whose shape is determined by the chosen kernel function.
			</p>
			<figure id="kde-construction" align="center">
				<img alt="Construction of KDE" src="img/kde.png" style="max-width: 400px;">
				<figcaption>Extracted from image by Drleft (CC BY-SA 3.0)</figcaption>
			</figure>
			<p>
				These bumps are then summed together to obtain the KDE, displayed in above plot as the solid blue line. In regions with many data points, the KDE will thus return large values since many bumps were summed together, whereas the KDE will return smaller values for regions with only few observations.
			</p>
			<p>
				Choosing an appropriate bandwidth is a delicate problem. Many solutions have been proposed, but there is no clear best one. For the sake of simplicity, we will employ a rule of thumb by Silverman that is often used in practice. For the data set above, the rule chooses the value <span class="tex" data-eqn="h = 1.55054"></span>. Let us store this in a variable of said name:
			</p>
			<pre><code language="javascript">
&gt; var h = 1.55054;</code></pre>
			</p>
			<aside class="special">
				<h3>Silverman's Rule</h3>
				<p>
					A commonly used rule of thumb for choosing the bandwidth is Silverman's reference bandwidth, which is defined as follows:
				</p>
				<span class="tex" data-eqn="h \approx 0.9 A n^{-1/5}" displayMode></span>
				<p>
					where <span class="tex" data-eqn="A = \min( \hat \sigma, IQR )"></span> is the minimum of the <a href="https://en.wikipedia.org/wiki/Standard_deviation">sample standard deviation</a> and the <a href="https://en.wikipedia.org/wiki/Interquartile_range">interquartile range</a>. A previous rule of thumb by Silverman uses the value 1.06 in place of 0.9, but this choice of bandwidth is prone to miss bimodality.
				</p>
			</aside>
			<p>
				For the kernel function, we will use the Gaussian kernel:
			</p>
			<pre><code language="javascript">
&gt; var K = base.dist.normal.pdf.factory( 0.0, 1.0 );</code></pre>
			<p>
				We have now everything in place to run generate a kernel density estimate for our data set and compare it with the true underlying distribution.	To overlay both the true distribution and our estimate on ome plot, let us first create a linearly spaced array of values between 0 and 14 using <code>linspace</code> at whose values we will evaluate the true density as well as our estimator.
			</p>
			<pre><code language="javascript">
&gt; var x = linspace( 0, 14, 200 );
&gt; var y1 = x.map( function( x ) { return truePDF( x ) } );
&gt; var y2 = x.map( function( x ) { return fhat( x, xs, K, h ) } );
&gt; var plt = plot( [x,x], [y1,y2] );
&gt; plt.colors = [ 'red', 'blue' ];</code></pre>
			<p>Let us render it into <code>#kde-plot</code>:
			<pre><code language="javascript">
&gt; var el2 = document.querySelector( '#kde-plot' );
&gt; el2.innerHTML = vdom2html( plt.render() );</code></pre>
			<figure id="kde-plot" align="center">
				<img alt="placeholder" src="img/plot_placeholder.png" style="max-width:400px;">
				<figcaption>Figure #kde-plot.</figcaption>
			</figure>
			<h3>Exercises</h3>
			<ul>
				<li>For the KDE, instead of choosing the bandwidth via Silverman's rule of thumb, pick both a very large and a very small bandwidth and visualize the results. Observe how the results change. One case should correspond to what is called <i>undersmoothing</i>, the other one <i>oversmoothing</i>. Can you see why?</li>
				<li>In this lab, we have been using the Gaussian kernel, but there are many other available <a href="https://en.wikipedia.org/wiki/Kernel_(statistics)">kernel functions</a>. You can use any kernel function with KDE, but different chocies will lead to estimates with different characteristics. The linked Wikipedia article contains a table with a long list of them. Pick one, implement it, and rerun your analysis.</li>
			</ul>
			<h3>Clustering using KDEs</h3>
			<p>
				Cluster analysis subsumes unsupervised learning methods that are concerned with the task of grouping observations together in a way that observations assigned to a common group are similar to each other but distinct from observations assigned to the other groups (called <i>clusters</i>). One of the most popular clustering algorithms is <a href="https://en.wikipedia.org/wiki/K-means_clustering">k-means clustering</a>, which is in large part due to its computational efficiency. However, one downside of <a href="https://en.wikipedia.org/wiki/K-means_clustering">k-means clustering</a> is that one has to specify the amount of clusters that one wishes to retrieve beforehand. We are now going to explore a less known clustring technique, which does not suffer from this shortcoming.
			</p>
			<p>
					As we can see, the distribution has two modes, one at the value two and the other at the value nine. We would expect observations generated from this distribution to roughly form two clusters. A clustering algorithm that can uncover these two clusters, without us having to tell the method that there are two groups, is <i>mode clustering</i>.
			</p>
			<p>
				Based on the nonparametric kernel density estimate of the distribution, <i>mode clustering</i> proceeds by finding the modes of the distribution via the so called mean-shift algorithm. Besides estimating the modes of the distribution, the algorithm performs clustering since it reveals what mode each point is attracted to. To perform mode clustering, we have to choose only one <i>tuning parameter</i>, the bandwidth of the underlying kernel density estimator. The mean-shift algorithm works as follows:
			</p>
			<aside class="special">
				<h3>Mean-Shift Algorithm</h3>
				<ol>
					<li>
						Input: A KDE and data points
						<span class="tex" data-eqn="x_1,\ldots,x_n"></span>
					</li>
					<li>
						For each point <span class="tex" data-eqn="x_j"></span>, set <span class="tex" data-eqn="a_j^{(0)} = x_j"></span>
						and iterate the following until convergence is achieved:
						<span class="tex" data-eqn="a_j^{(s+1)} = \frac{\sum_{i=1}^n x_i K\left( \tfrac{a_j^{(s)}-x_i}{h} \right)}{ \sum_{i=1}^n K\left( \tfrac{a_j^{(s)}-x_i}{h} \right)}" displayMode></span>
					</li>
				</ol>
			</aside>

		<h3>Exercises</h3>
		<ul>
			<li>
				<p>
					Implement the mean-shift algorithm and obtain the cluster assignments for the data:
				</p>
				<pre><code language="javascript">
&gt; function meanShift( xs, K, h ) {
    var a = copy( xs );
    for ( var j = 0; j &lt; a.length; j++ ) {
        // Code comes here...
    }
    return a;
}</code></pre>
				<p>
					Hint: Instead of checking for convergence at each iteration, in a first pass it might be easier to just run the algorithm for a sufficiently large number of iterations (say a few hundred).
				</p>
			</li>
		</ul>

			<h3>Survey</h3>
			<google-codelab-survey survey-id="kdes-and-clustering">
				<h4>Did you find this lab useful?</h4>
				<paper-radio-group>
					<paper-radio-button>Not useful</paper-radio-button>
					<paper-radio-button>Somewhat useful</paper-radio-button>
					<paper-radio-button>Useful</paper-radio-button>
					<paper-radio-button>Very useful</paper-radio-button>
				</paper-radio-group>

				<h4>How do you feel about the length of this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Too short</paper-radio-button>
					<paper-radio-button>Just right</paper-radio-button>
					<paper-radio-button>Too long</paper-radio-button>
				</paper-radio-group>

				<h4>Apart from the final exercises, how difficult did you find this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Very Easy</paper-radio-button>
					<paper-radio-button>Easy</paper-radio-button>
					<paper-radio-button>Just Right</paper-radio-button>
					<paper-radio-button>Difficult</paper-radio-button>
					<paper-radio-button>Very Difficult</paper-radio-button>
				</paper-radio-group>

				<h4>How difficult did you find the exercises for this lab?</h4>
				<paper-radio-group>
					<paper-radio-button>Very Easy</paper-radio-button>
					<paper-radio-button>Easy</paper-radio-button>
					<paper-radio-button>Just Right</paper-radio-button>
					<paper-radio-button>Difficult</paper-radio-button>
					<paper-radio-button>Very Difficult</paper-radio-button>
				</paper-radio-group>
			</google-codelab-survey>

		</google-codelab-step>

		<!-- Conclusion -->

		<google-codelab-step label="Conclusion" duration="2">
			<p>
				Congratulations! We hope that we have successfully introduced you to data science in JavaScript and inspired you to continue learning more. Be sure to check out <a title="A standard library for Node.js and JavaScript" href="https://github.com/stdlib-js/stdlib">stdlib</a> for more information and follow the project on <a title="stdlib GitHub repository" href="https://github.com/stdlib-js/stdlib">GitHub</a> and <a title="stdlib on Twitter" href="https://twitter.com/stdlibjs">Twitter</a> to receive updates on the latest developments.
			</p>
			<p>
				Lastly, if you are at <a title="FullStack London 2017" href="https://skillsmatter.com/conferences/8264-fullstack-2017-the-conference-on-javascript-node-and-internet-of-things">FullStack London 2017</a>, go high-five a workshop facilitator and ask for a sticker. :)
			</p>
			<div align="center">
				<a title="stdlib sticker" href="https://github.com/stdlib-js/stdlib">
					<img alt="stdlib" src="img/sticker.png" style="max-width: 200px;">
				</a>
			</div>

			<h3>Survey</h3>
			<google-codelab-survey survey-id="workshop">
				<h4>How often do you use JavaScript for data science tasks (e.g., data exploration, machine learning, and statistical analysis)?</h4>
				<paper-radio-group>
					<paper-radio-button>Never</paper-radio-button>
					<paper-radio-button>Rarely</paper-radio-button>
					<paper-radio-button>Sometimes</paper-radio-button>
					<paper-radio-button>Frequently</paper-radio-button>
					<paper-radio-button>Everyday</paper-radio-button>
				</paper-radio-group>

				<h4>Did you find this workshop useful?</h4>
				<paper-radio-group>
					<paper-radio-button>Not useful</paper-radio-button>
					<paper-radio-button>Somewhat useful</paper-radio-button>
					<paper-radio-button>Useful</paper-radio-button>
					<paper-radio-button>Very useful</paper-radio-button>
				</paper-radio-group>

				<h4>How do you feel about the length of this workshop?</h4>
				<paper-radio-group>
					<paper-radio-button>Too short</paper-radio-button>
					<paper-radio-button>Just right</paper-radio-button>
					<paper-radio-button>Too long</paper-radio-button>
				</paper-radio-group>

				<h4>How difficult did you find this workshop?</h4>
				<paper-radio-group>
					<paper-radio-button>Very Easy</paper-radio-button>
					<paper-radio-button>Easy</paper-radio-button>
					<paper-radio-button>Just Right</paper-radio-button>
					<paper-radio-button>Difficult</paper-radio-button>
					<paper-radio-button>Very Difficult</paper-radio-button>
				</paper-radio-group>

				<h4>Are you more likely to use JavaScript for data science after completing this workshop?</h4>
				<paper-radio-group>
					<paper-radio-button>No</paper-radio-button>
					<paper-radio-button>Maybe</paper-radio-button>
					<paper-radio-button>Yes</paper-radio-button>
				</paper-radio-group>

				<h4>How would you rate <a title="A standard library for Node.js and JavaScript" href="https://github.com/stdlib-js/stdlib">stdlib</a>?</h4>
				<paper-radio-group>
					<paper-radio-button>Never heard of it</paper-radio-button>
					<paper-radio-button>Awful</paper-radio-button>
					<paper-radio-button>Poor</paper-radio-button>
					<paper-radio-button>Needs work</paper-radio-button>
					<paper-radio-button>Meh</paper-radio-button>
					<paper-radio-button>Okay</paper-radio-button>
					<paper-radio-button>Good</paper-radio-button>
					<paper-radio-button>Awesome</paper-radio-button>
				</paper-radio-group>
			</google-codelab-survey>

		</google-codelab-step>

	</google-codelab>

	<!-- Scripts -->
	<script type="text/javascript" src="js/bundle.js"></script>
	<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js" integrity="sha384-/y1Nn9+QQAipbNQWU65krzJralCnuOasHncUFXGkdwntGeSvQicrYkiUBwsgUqc1" crossorigin="anonymous"></script>
	<script type="text/javascript">
		(function() {
			'use strict';

			/**
			* Renders a TeX equation.
			*
			* @private
			* @param {DOMElement} el - element to render
			*/
			function render( el ) {
				var attr = el.getAttribute( 'data-eqn' );
				if ( el.hasAttribute( 'displayMode' ) ) {
					katex.render( attr, el, {
						'displayMode': true
					});
				} else {
					katex.render( attr, el );
				}
			} // end FUNCTION render()

			/**
			* Callback invoked upon page load.
			*
			* @private
			*/
			function onLoad() {
					var elements;
					var i;

					elements = document.querySelectorAll( '.tex' );
					for ( i = 0; i < elements.length; i++ ) {
						render( elements[ i ] );
					}
			} // end FUNCTION onLoad()

			window.onload = onLoad;
		})();
	</script>
	<script type="text/javascript">
		(function() {
			'use strict';

			var URL = 'https://script.google.com/macros/s/AKfycbzWMQ-I34MrI4HePla1aoU4nLTZGD8rlTHT2GwFaPYFAXGxHPc/exec';

			window.addEventListener( 'google-codelab-survey-answer', onSurvey );

			function onSurvey( evt ) {
				var xhttp;
				var blob;
				var id;

				id = evt.srcElement.attributes[ 0 ].value;

				blob = 'id='+id;
				blob += '&question='+evt.detail.question;
				blob += '&answer='+evt.detail.answer;

				xhttp = new XMLHttpRequest(); // TODO: account for older IE browsers
				xhttp.onreadystatechange = onReady;
				xhttp.open( 'POST', URL, true );
				xhttp.setRequestHeader( 'Content-type', 'application/x-www-form-urlencoded' );
				xhttp.send( blob );
			}

			function onReady() {
				// No-op...
			}

		})();
	</script>

</body>
</html>
